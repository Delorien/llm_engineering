{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> 34cab25 (Completing week1 day2 exercise)
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Automating content creation for social media, blogs, and websites, such as generating product descriptions, blog posts, and even entire articles.\n",
      "2. **Product Design**: Using Generative AI to design products, logos, and packaging, which can help companies save time and money on design costs.\n",
      "3. **Image and Video Generation**: Creating high-quality images and videos for advertising, marketing, and e-commerce purposes, such as product showcases and social media content.\n",
      "4. **Chatbots and Virtual Assistants**: Developing chatbots and virtual assistants that use Generative AI to provide personalized customer support and improve user experience.\n",
      "5. **Recommendation Systems**: Using Generative AI to generate personalized product recommendations based on user behavior and preferences.\n",
      "6. **Predictive Maintenance**: Analyzing sensor data from machines and equipment to predict maintenance needs, reducing downtime and increasing efficiency.\n",
      "7. **Marketing Campaign Optimization**: Generating targeted marketing campaigns using Generative AI, such as personalized email templates and social media ads.\n",
      "8. **Financial Analysis**: Using Generative AI to analyze large datasets and identify trends, patterns, and predictions in financial markets.\n",
      "9. **Customer Service**: Automating customer service tasks such as answering common questions, providing support, and generating responses to customer inquiries.\n",
      "10. **Innovation and Idea Generation**: Using Generative AI to generate new ideas and solutions for business problems, such as product development and process improvement.\n",
      "\n",
      "Some specific examples of companies using Generative AI include:\n",
      "\n",
      "* **Content generation:** Automated content creation platform WordLift uses Generative AI to generate blog posts, articles, and social media content.\n",
      "* **Product design:** Design software company Autodesk uses Generative AI to help architects and designers create more efficient buildings and products.\n",
      "* **Image and video generation:** Advertising agency Wieden+Kennedy used Generative AI to create high-quality images for a major brand's ad campaign.\n",
      "* **Chatbots and virtual assistants:** Retailer H&M uses Generative AI-powered chatbots to provide customer support and answer frequently asked questions.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can help reduce content creation costs and improve content consistency.\n",
      "2. **Product Design**: Generative AI can be used to design new products, such as 3D models, logos, and packaging designs. This can help speed up the product development process and reduce costs associated with traditional design methods.\n",
      "3. **Image and Video Generation**: Generative AI can generate high-quality images and videos that can be used for various applications, such as advertising, marketing, and entertainment.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI can be used to power chatbots and virtual assistants that provide customer support, answer frequently asked questions, and offer personalized recommendations.\n",
      "5. **Predictive Analytics**: Generative AI can analyze large datasets and generate predictions about future trends, sales, and customer behavior. This can help businesses make data-driven decisions and improve their overall strategy.\n",
      "6. **Marketing Automation**: Generative AI can be used to automate marketing campaigns by generating personalized emails, social media posts, and other content that resonates with customers.\n",
      "7. **Product Recommendation Systems**: Generative AI can generate product recommendations based on customer behavior, preferences, and purchase history. This can help businesses improve customer engagement and increase sales.\n",
      "8. **Financial Analysis**: Generative AI can analyze large financial datasets and generate insights about market trends, stock prices, and investment opportunities.\n",
      "9. **Risk Management**: Generative AI can be used to identify potential risks and vulnerabilities in business operations, such as supply chain disruptions or cyber threats.\n",
      "10. **Customer Service**: Generative AI can power chatbots and virtual assistants that provide personalized customer support, answer frequently asked questions, and offer solutions to common issues.\n",
      "\n",
      "Some specific examples of businesses using generative AI include:\n",
      "\n",
      "* **DALL-E**, a generative AI model developed by OpenAI, is being used by companies like Adobe, Autodesk, and Coca-Cola to generate high-quality images and videos.\n",
      "* **Chatbots** powered by generative AI are being used by companies like IBM, Microsoft, and Salesforce to provide customer support and answer frequently asked questions.\n",
      "* **Product design** tools like Generative Parts, developed by Materialise, use generative AI to help designers create new product designs.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries and domains.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 7,
   "id": "b8f38e95-2855-437d-b915-13ec7aafea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68fb1cd2-e31c-48d2-bb17-fe915b62a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1d6973-a322-40d9-984e-35cee8bcaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e900f7c-f8db-4136-b731-1e05974c67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d52f253-816c-47dd-b654-5dc7bb7adfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "652d8044-ae00-4ca3-b8cf-2c0a2e0552da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7833c182-0503-4227-88a1-c763415e1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "\n",
    "    response = ollama.chat(model=MODEL, messages=messages_for(website))\n",
    "\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8503d9-7569-4830-b3a5-8a32db07e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e3247db-ed10-4513-a367-17ffe339009a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There is no specific question in the provided text, but I can help you with a summary of the topics covered or provide information on various subjects mentioned.\n",
       "\n",
       "**Summary of Topics:**\n",
       "\n",
       "1. **Sports:** The Super Bowl and other sports events were featured, including stunning photographs capturing starling migrations.\n",
       "2. **Technology:** Apple and Google restored TikTok to their US app stores, Elon Musk withdrew his nearly $100 billion bid for OpenAI if it remains a nonprofit, and Duolingo's cute owl mascot is dead.\n",
       "3. **Health and Wellness:** Experts discussed the secret to great sex, the risks of excessive coffee consumption, and how much coffee is too much according to a doctor.\n",
       "4. **Business and Finance:** Markets were discussed, including pre-markets, after-hours, and fear & greed indicators.\n",
       "5. **Politics:** The US election was covered, with Friedrich Merz, Merkel's rival and German election frontrunner, making headlines. Additionally, Vance turned on European allies in a blistering speech that downplayed threats from Russia and China.\n",
       "\n",
       "**General Topics:**\n",
       "\n",
       "1. **International Relations:** Fighting in Africa's mineral-rich DRC killed over 3,000 in less than 2 weeks, and Georgia slid into authoritarianism as protesters vow to keep fighting Russian pivot.\n",
       "2. **Environment and Climate Change:** The climate crisis was discussed, including the impact of Ukraine-Russia War and Israel-Hamas War on the environment.\n",
       "3. **Science and Space:** Stunning photographs capturing starling migrations and breakthroughs in space exploration were featured.\n",
       "\n",
       "Please let me know if you would like more specific information or clarification on any of these topics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d481bc-5a99-4617-9f52-5d3beaa0444d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Website Summary\n",
       "### About the Creator\n",
       "\n",
       "Ed is a writer, programmer, and entrepreneur who enjoys experimenting with Large Language Models (LLMs). He's the co-founder and CTO of Nebula.io, an AI company that applies LLMs to help people discover their potential.\n",
       "\n",
       "### Projects and Ventures\n",
       "\n",
       "* Co-founder and CTO at Nebula.io\n",
       "\t+ Applying AI to talent management and discovery\n",
       "\t+ Patenting a proprietary matching model for LLMs\n",
       "* Founder and CEO of untapt (acquired in 2021)\n",
       "\t+ Founded an AI startup focused on talent management\n",
       "* Host of various online workshops and resources, including:\n",
       "\t+ LLM Workshop – Hands-on with Agents\n",
       "\t+ Mastering AI and LLM Engineering\n",
       "\t+ From Software Engineer to AI Data Scientist\n",
       "\n",
       "### News and Announcements\n",
       "\n",
       "* **January 23, 2025**: Upcoming LLM Workshop announcement\n",
       "* **December 21, 2024**: Welcome message for SuperDataScientists\n",
       "* **November 13, 2024**: Announcement of a new resource for Mastering AI and LLM Engineering\n",
       "* **October 16, 2024**: Introduction to resources for transitioning from Software Engineer to AI Data Scientist\n",
       "\n",
       "### Contact Information\n",
       "\n",
       "Ed is available at `ed [at] edwarddonner [dot] com` and can be found on LinkedIn, Twitter, Facebook, and through the website's newsletter subscription."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
>>>>>>> 34cab25 (Completing week1 day2 exercise)
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.11"
=======
   "version": "3.11.4"
>>>>>>> 34cab25 (Completing week1 day2 exercise)
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
